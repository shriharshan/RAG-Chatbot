sensor letter deeplearningbased detection infant autism spectrum disorder using autoencoder feature representation jung hyuk lee1 geon woo lee1 guiyoung bong2 hee jeong yoo23and hong kook kim1 1school electrical engineering computer science gwangju institute science technology gwangju 61005 korea ljh0412gistackr geonwoo0801gistackr 2department psychiatry seoul national university bundang hospital seongnamsi gyeonggido 13620 korea 20409snubhorg hjyoosnuackr 3department psychiatry college medicine seoul national university seoul 03980 korea correspondence hongkookgistackr received 29 october 2020 accepted 24 november 2020 published 26 november 2020 gid00030gid00035gid00032gid00030gid00038gid00001gid00033gid00042gid00045 gid00001 gid00048gid00043gid00031gid00028gid00047gid00032gid00046 abstract autism spectrum disorder developmental disorder lifespan disability diagnostic instrument developed qualiﬁed based accuracy discrimination child asd typical development child stability procedure disrupted limitation pertaining time expense subjectivity clinician consequently automated diagnostic method developed acquiring objective measure autism various ﬁelds research vocal characteristic reported distinctive characteristic clinician also shown promising performance several study utilizing deep learning model based automated discrimination child asd child td however di culties still exist term characteristic data complexity analysis lack arranged data caused low accessibility diagnosis need secure anonymity order address issue introduce pretrained feature extraction autoencoder model joint optimization scheme achieve robustness widely distributed unreﬁned data using deeplearningbased method detection autism utilizes various model adopting autoencoderbased feature extraction joint optimization extended version geneva minimalistic acoustic parameter set speech feature data set acquire improved performance detection asd infant compared raw data set keywords autoencoder bidirectional long shortterm memory joint optimization acoustic feature extraction autism spectrum disorder 1 introduction autism spectrum disorder developmental disorder high probability causing diculties social interaction people 1 according diagnostic statistical manual mental disorder fifth edition asd involves several characteristic conﬁned speciﬁc interest behavior delayed linguistic development poor functionality term communicating functioning social situation 2 wide variation term type severity asd based characteristic disorder referred spectrum 1 asd characteristic developmental disorder lifespan disability prevalence also increasingfrom 1 150 child 2000 1 54 child 2016 3 diverse evidence obtained previous research showing chance improvement sensor 2020 20 6762 doi103390 s20236762 wwwmdpicom journal sensorssensors 2020 20 6762 2 11 social ability people asd increase earlier clinical intervention performed 4 early detection asd characteristic become key point current asd research various instrument discriminating asd developed commonly accepted gold standard scheme behavioral assessment timeconsuming procedure require multidisciplinary team however behavioral assessment su er term stability asd diagnosis result issue accessibility subjectivity interpretive bias profession 5 therefore several attempt develop objective precise diagnostic method made multiple ﬁelds genetic determination 6 principle analysis brain image 7 physiological approach 8 one prominent area behavioral observation infant vocal characteristic child asd known abnormality prosody resulting deﬁcits ability recognize inherent mental condition others 9 atypical vocalization known monotonous exaggerated revealed using various acoustic characteristic followed engineering approach discrimination asd typical development child based vocal acoustic feature example 10 researcher estimated deﬁcits vocalization child asd average age 18 month ﬂat intonation atypical pitch control volume based variability pitch longterm average spectrum using fast fourier transform signiﬁcant di erences observed spectral component lowband frequency well spectral peak larger pitch range standard deviation development linguistic ability also considered distinguishable feature delayed development child asd earlier vocal pattern age 618 month proven di erentiable study 11 aimed conﬁrm hypothetical vocal pattern social quality vocal behavior order di erentiate asd td cohort group child aged 06 612 1218 month term categorized speech pattern consisting vocalization long reduplicated babbling twosyllable babbling ﬁrst word evidence abnormality child asd shown case signiﬁcant decrease vocalization ﬁrst word rate di erence babbling ability child asd td negligible given development improvement machine learning algorithm achievement performance stateoftheart classiﬁcation discrimination task 12 recent attempt develop automated classiﬁcation method based machine learning technique based distinctiveness vocal characteristic shown promising alternative conventional method many publication 13 example machine learning classiﬁcation researcher 14 employed various acousticprosodic feature including fundamental frequency formant frequency harmonic root mean square signal energy research support vector machine probabilistic neural network adopted classiﬁers showed e ectual accuracy discriminating child asd child td meanwhile author 15 employed recent deep learning technique convolutional neural network recurrent neural network spectral feature shorttime fourier transform constant q transform classify child diagnosed using autism diagnostic observation schedule also showing promising result multiple outcome svms rnns combination cnn rnn classiﬁers generalized acoustic feature set extended version geneva minimalistic acoustic parameter set 16 bidirectional long shortterm memory model adopted di erentiate child asd child td 17 showing 75 subject utterance correctly classiﬁed simple application deep learning model feature set quality previous research based various acoustic feature proven e ectiveness acoustic feature classiﬁcation algorithm detection abnormality childrens voice asd group compared td group complexity relationship inherent feature remain uncertain large amount data accumulated furthermore limitation still remains term problem regarding data collection since aresensors 2020 20 6762 3 11 diculties pertaining need secure anonymity infant subject well unintended ignorance parent earlier stage infant development data infant accordingly dispersed gender age number vocalization consist comparably small volume audio engineering data general problem typically overlooked previous research controlled small amount data order provide suggestion method overcome abovementioned restriction focus examining feasibility neural network feature extractor employing autoencoder modify acoustic feature lowered separable feature dimension 18 construct simple sixlayered stacked ae contains input layer three fully connected layer output layer one auxiliary output layer categorical target asd td optimization latent feature space ae train ae deep learning model compare result model based svms vanilla blstm adopting model parameter method suggested 17 remainder paper organized follows section 2 describes speciﬁcations participant data data processing feature extraction statistical analysis experimental setup section 3 present performance evaluation algorithm svms vanilla blstm lastly section 4 concludes paper 2 proposed method 21 data collection acoustic feature extraction study based audio data video recording asd diagnosis collected 2016 2018 seoul national university bundang hospital received approval institutional review board snubh use fully anonymized data retrospective analysis existing research collected audio data 39 infant assessed using seven multiple instrument consisting ado second edition autism diagnostic interview revised behavior development screening toddler interview behavior development screening toddler play korean version childhood autism rating scale reﬁned cars2 social communication questionnaire social responsiveness scale 1922 ﬁnal diagnosis based best clinical estimate diagnosis according dsm5 asd criterion licensed child psychiatrist using available participant information participant age ranged 6 24 month average age 1920 month standard deviation 252 month note age mean age time infant visited hospital undergo initial diagnosis examination four male six female diagnosed asd whose average age 1472 month sd 245 remaining participant consisted td child display collected data distribution show detailed information collected data infant distribution age gender age subject diagnosed asdno subject diagnosed tdno infant subject 612 month 0 5 1 f 5 1 f 1218 month 1 3 f 14 9 f 15 12 f 1824 month 3 3 f 0 3 3 f age 1920 252 1472 245 1592 317sensors 2020 20 6762 4 11 detailed information age gender initial deﬁnite diagnosis date infant infant idage initial diagnosis dategenderinitial diagnosis date deﬁnite final diagnosis date asd td 1 18 male 2018 0728 2018 0828 td 2 18 male 2017 0727 2017 0827 td 3 10 male 2018 0810 2018 0910 td 4 13 male 2017 0610 2017 0710 td 5 22 female 2018 0131 2018 0228 asd 6 16 male 2018 0317 2018 0417 td 7 17 female 2018 0630 2018 0730 td 8 14 female 2018 0106 2018 0206 td 9 18 male 2018 0717 2018 0817 td 10 14 male 2017 1104 2017 1204 td 11 17 female 2017 0629 2017 0729 asd 12 12 female 2018 0120 2018 0220 td 13 9 male 2017 0218 2017 0318 td 14 18 female 2017 0304 2017 0404 asd 15 18 male 2018 0519 2018 0619 td 16 24 female 2018 0808 2018 0908 asd 17 19 male 2018 0224 2018 0324 asd 18 19 male 2017 0418 2017 0518 asd 19 18 female 2017 0304 2017 0404 td 20 12 male 2016 1231 2017 0131 td 21 16 female 2018 0316 2018 0416 td 22 20 male 2017 1014 2017 1114 asd 23 15 male 2018 0509 2018 0609 asd 24 17 female 2017 0204 2017 0304 td 25 16 male 2018 0317 2018 0417 td 26 12 male 2018 0329 2018 0429 td 27 17 female 2017 0125 2017 0225 td 28 17 male 2018 0208 2018 0308 asd 29 14 male 2018 0113 2018 0213 td 30 16 male 2016 1130 2016 1230 td 31 12 male 2017 0322 2017 0422 td 32 15 male 2017 0311 2017 0411 td 33 16 male 2017 1205 2018 0105 td 34 13 female 2017 1213 2018 0113 td 35 15 female 2017 0325 2018 0425 td 36 13 male 2018 0825 2018 0925 td 37 21 male 2017 0624 2017 0724 asd 38 14 male 2017 0222 2017 0322 td 39 14 male 2018 0127 2018 0227 td infant audio data recorded clinical procedure elicit behavior infant attendance one doctor clinician one parent child clinical area audio component consisted various speech child clinician parent well noise toy dragging chair note recording done one two typical clinical room snubh room dimension 365 cm400 cm270 cm 350 cm350 cm270 cm hospital noise level around 40 db order analyze vocal characteristic infant audio clip processed split audio segment containing infant voice disturbed music clattering noise toy overlapped voice clinician parent segment classiﬁed one ﬁve category labeled 0 4 measuring data distribution label intended show di erentiable characteristic relative childrens linguistic development 0 one syllable shortsensors 2020 20 6762 5 11 momentary single vocalization ah ba 1 two syllable commonly denoted canonical babbling reduplication clear babbling two identical variant syllable baba baga 2 babbling containing syllable 3 ﬁrst word mother father 4 atypical voice including screaming cry distribution type vocalization second shown number vocalization per category presented along rational value considering di erence asd td group data unbalanced small distribution asd td vocalization show tendency reported 10 asd group showed signiﬁcantly lower ratio ﬁrst word increased ratio atypical vocalization revealing developmental delay linguistic ability amount type vocalization second vocal label asd td 0 80134 267897 1 314405 443498 2 33241 34766 3 8311 57286 4 333400 266794 total 769491 1070241 acquiring qualiﬁed e ective feature set vocal data egemaps employed voice feature extraction gemaps popular feature set providing minimalistic speech feature generally utilized automatic voice analysis rather large brute force parameter set extended version egemaps contains 88 acoustic feature fully utilized experiment recorded set audio data stored 48 khz stereo ﬁle downsampled downmixed 16 khz monoaudio ﬁle taking consideration usability resolution melfrequency cepstral coecients extract speech feature asd classiﬁcation infant utterance segmented 25 m frame 10 m overlap frame 88 di erent feature egemaps extracted frame open source speech music interpretation using largespace extraction toolkit 23 feature normalized mean standard deviation normalization scaling acquired ﬁxed normalizing factor training data set feature grouped ﬁve frame considering timerelevant characteristic speech data 22 pretrained ae acoustic feature process reﬁne acoustic data featureextracting ae introduced ae hierarchical structure trained regression model reproducing input parameter ae take input convert latent representation reconstructs input parameter latent value 24 consider input ae x2rd latent representation z2rd0 reconstruction input y2rdare obtained applying nonlinear activation function fto weight sum zusing weighting matrix w2rdd0and bias vector b2rd0 zf wtxb yf wtzb0 ti matrix transpose operator latent dimension d0d output latent layer considered compressed meaningful value extracted input also noted bottleneck feature 25 normalized egemaps feature applied train featureextracting ae applying data input target ae model contained latent layer lowered compacted feature dimension compared input layer achieve useful bottleneck featuresensors 2020 20 6762 6 11 model symmetrically structured centering around latent layer model could divided two component encoder consisting layer input latent layer decoder consisting layer bottleneck output layer ae structure depicted ae model consisted fc layer dimension 88 70 54 70 88 node input hidden latent hidden output layer respectively hidden dimension selected experimentally bottleneck feature dimension used comparison previous research 17 54 feature selected considering statistical dissimilarity distribution asd td feature based mannwhitney u test 26 additionally introduced auxiliary output binary categorical target asd td known semisupervised method train ae model e ectively 27 auxiliary output depicted aux reconstructed feature auxiliary classiﬁcation written zif z1f yrecw34z3b34 yaux yrecrefers reconstructed egemaps feature yauxis auxiliary classiﬁcation result fis activation function softmax activation sensor 2020 20 x peer review 6 12 matrix transpose operator latent dimension 𝑑𝑑 output latent layer considered compressed meaningful value extracted input also noted bottleneck feature 25 normalized egemaps feature applied train feature extracting ae applying data input target ae model contained latent layer lowered compacted feature dimension compared input layer achieve useful bottleneck feature model symmetrically structured centering around latent layer model could divided two component encoder consisting layer input latent layer decoder consisting layer bottleneck output layer ae structure depicted ae model consisted fc layer dimension 88 70 54 70 88 node input hidden latent hidden output layer respectively hidden dimension selected experimentally bottleneck feature dimension used comparison previous research 17 54 feature selected considering statistical dissimilarity distribution asd td feature based mann whitne u test 26 additionally introduced auxiliary output binary categorical target asd td known semi supervised method train ae model effectively 27 auxiliary output depicted aux reconstructed feature auxiliary classification written 𝒛𝑖𝑓 𝒛1𝑓 𝒚𝑟𝑒𝑐𝑾34𝒛3𝒃34 𝒚𝑎𝑢𝑥 𝒚𝑟𝑒𝑐 refers reconstructed egemaps feature 𝒚𝑎𝑢𝑥 auxiliary classification result 𝑓 activation function softmax activation structure semi supervised auto encoder model egemaps extended version geneva minimalistic acoustic parameter set asd autism spectrum disorder td typical development loss reconstruction error main ae target measured using mean absolute error auxiliary asdtd arget loss binary cross entropy added simultaneously optimized rational hyper parameter overall loss equation structure semisupervised autoencoder model egemaps extended version geneva minimalistic acoustic parameter set asd autism spectrum disorder td typical development loss reconstruction error main ae target measured using mean absolute error auxiliary asd td target loss binary crossentropy added simultaneously optimized rational hyperparameters overall loss equation lrecon 1 nnx i1 yirecyigt lauxy1gtlogy1gtlog ltotallrecon laux lreconlaux ltotaldenote reconstruction error auxiliary loss using binary crossentropy loss function total loss respectivelysensors 2020 20 6762 7 11 stacked ae model rational value 03was selected experimentally considering proportion loss order train ae e ectively l2 normalization weight normalization batch normalization adopted 2829 training completed fetched encoder ae feature extraction part joint optimization model training procedure deep learning model 23 establishing training deep learning model asd detection egemaps data set ae trained semisupervised learning machine learning model svms blstm joint optimized blstm constructed model input parameter dimension output target asd td classiﬁcation label egemaps feature data paired diagnostic result supervised learning neural network model binary decision asd labeled positive data point label td labeled negative data point composed four kind model paired data svms linear kernel vanilla blstm 88 egemaps feature vanilla blstm 54 egemaps feature jointly optimized blstm layer ae joint optimization model depicted data set prepared input ﬁve sequential frame ie grouped egemaps feature svms received single frame parameter 440 dimension ﬂattened original ﬁve input frame deep learning model batch normalization rectangular linear unit activation dropout applied layer except output layer 3031 adaptive momentum optimizer 32 used train network training procedure controlled early stopping minimizing validation error 100 epoch patience saving best model improvement validation loss epoch amount speech data relatively small deep learning model compared disparate ﬁeld audio engineering grouped data ﬁve segment test utterance separated formerly selected randomly 10 total data evenly distributed across vocalization type underwent ﬁvefold crossvalidation training bestperforming model chosen model trained tensorflow framework 33 comparison svm model linear kernel trained data split proposed deep learning model well vanilla blstm suggested 17 single blstm eight cell sensor 2020 20 x peer review 8 12 structure joint optimization model auto encoder bidirectional long short term memory 3 performance evaluation performance method evaluated five fold cross validation 95 average asd utterance 130 average td utterance proportionally distributed five case vocalization gener alized estimation unconcentrated utterance data averaged performance five validation split model described labeled name blstm used feature training blstm model egemaps 88 deno te 88 feature egemaps egemaps 54 denotes 54 feature selected mann whitney u test aeencoded denotes joint optimized model classification stage one utterance processed frame wise method softmax output c onverted class index 0 1 average class index frame 05 utterance considered asd child utterance performance scored conventional measure well unweighted average recall weighted average recall chosen interspeech 2009 emotion challenge considered imbalanced class 34 experiment svm model showed low precision extremely biased toward td class blstm classifi er 88 feature egemaps ae model showed considerable quality term classifying asd td child ae model showed marginal improvement correctly classifying child asd compared egemaps 88 54 selected feature showed degraded quality compared egemaps 88 obtaining biased result toward child td classification result support vector machine blstm 88 54 egemaps feature 54 selected egemaps feature b lstm ae encoded feature model svm blstm blstm blstm predicted asd td asd td asd td asd td asd 62 18 170 103 196 99 215 98 td 413 632 305 547 279 551 260 552 accuracy 06178 06373 06640 06818 precision 01305 03579 04126 04526 recall 07750 06227 06644 06869 f1 score 02234 04545 05091 05457 uar 05514 05997 06302 06509 uar unweighted average recall structure joint optimization model autoencoder bidirectional long shortterm memory 3 performance evaluation performance method evaluated ﬁvefold cross validation 95 average asd utterance 130 average td utterance proportionally distributed ﬁvesensors 2020 20 6762 8 11 case vocalization generalized estimation unconcentrated utterance data averaged performance ﬁve validation split model described labeled name blstm used feature training blstm model egemaps88 denotes 88 feature egemaps egemaps54 denotes 54 feature selected mannwhitney utest aeencoded denotes joint optimized model classiﬁcation stage one utterance processed framewise method softmax output converted class index 0 1 average class index frame 05 utterance considered asd child utterance performance scored conventional measure well unweighted average recall weighted average recall chosen interspeech 2009 emotion challenge considered imbalanced class 34 experiment svm model showed low precision extremely biased toward td class blstm classiﬁer 88 feature egemaps ae model showed considerable quality term classifying asd td child ae model showed marginal improvement correctly classifying child asd compared egemaps88 54 selected feature showed degraded quality compared egemaps88 obtaining biased result toward child td classiﬁcation result support vector machine blstm 88 54 egemaps feature 54 selected egemaps feature blstm aeencoded feature model svmblstm blstm blstm predicted asd td asd td asd td asd td asd 62 18 170 103 196 99 215 98 td 413 632 305 547 279 551 260 552 accuracy 06178 06373 06640 06818 precision 01305 03579 04126 04526 recall 07750 06227 06644 06869 f1 score 02234 04545 05091 05457 uar 05514 05997 06302 06509 uar unweighted average recall 4 discussion vanilla blstm model presented 17 conducted discrimination wellclassiﬁed subject 10monthold child sorted 54 feature egemaps distinctive distribution asd td selected mannwhitney utest using threefold crossvalidation method however di erence data distribution failed achieve egemaps feature selection test classiﬁcation result speciﬁed feature set presented herein application identical model structure adoption feature domain allow approach indirectly comparable result interpreted data distribution performed tstochastic neighbor embedding analysis 35 training data set nonlinearly squeeze data dimension based machine learning algorithm show data distribution twodimensional scatter plot ﬁgure egemaps feature egemaps88 egemaps54 showed almost identical distribution except amount asd outlier implies asd td feature egemaps feature show similar distribution experiment shown 16 egemaps includes temporal feature relevant vocalization utterance thus feature might cause confusion regarding discrimination asd td aeencoded feature however showed redistributed feature map characteristic distribution compared egemaps feature aeencoded feature compressed bottleneck feature derived weighting matrix paying attention signiﬁcant parameterssensors 2020 20 6762 9 11 reducing inﬂuence ambiguous parameter joint optimization model achieved marginally improved result compared egemaps88 distribution feature map would noticeable improved feature extraction model well di erentiable complex model although blstm eight cell employed comparison conventional research experiment sensor 2020 20 x peer review 9 12 4 discussion vanilla blstm model presented 17 conducted discrimination well classified subject 10 month old child sorted 54 feature egemaps distinctive distribution asd td selected mann whitney u test using three fold cross validation method however difference data distribution failed achieve egemaps feature selection test classification result specified feature set presented herein applicatio n identical model structure adoption feature domain allow approach indirectly comparable result interpreted data distribution performed stochastic neighbor embedding analy si 35 training data set nonlinearly squeeze data dimension based machine learning algorithm show data distribution twodimensional scatter plot figure egemaps feature egemaps 88 egem aps 54 showed almost identical distribution except amount asd outlier implies asd td feature egemaps feature show similar distribution experiment shown 16 egemaps includes temporal feature relevant vocalization utterance thus feature might cause confusion regarding discrimination asd td aeencoded feature however showed redistributed feature map characteristic distribution compared egemaps feature ae encoded feature compressed bottleneck feature derived weighting matrix paying attention significant parameter reducing influence ambiguous parameter joint optimization model achieved marginally improved result compared egemaps 88 distribution feature map would noticeable improved feature extraction model well differentiable complex model alt hough blstm eight cell employed comparison conventional research experiment overall performance score comparably low general classification problem account subjectivity complexity problem limitation term shortage data result jointly optimized model imply possibility deep learning based feature extraction improvement automated asdtd diagnosis restricted circumstance two dimensional scatter plot egemaps 88 egemaps 54 ae processed stochastic neighbor embedding 5 conclusion paper conducted experiment discovering possibility auto encoder based feature extraction joint optimization method automated detection atypicality voice child asd early developmental stage un der condition insufficient dispersed data set clas sification result relatively poor comparison general classification task based deep learning although investigation used limited number subject unbal anced data set suggested auto encoder based feature extraction joint optimization method revealed possibility feature dimension slight improvement model based diagnosis uncertain circumstance twodimensional scatter plot egemaps88 egemaps54 ae processed tstochastic neighbor embedding overall performance score comparably low general classiﬁcation problem account subjectivity complexity problem limitation term shortage data result jointly optimized model imply possibility deeplearningbased feature extraction improvement automated asd td diagnosis restricted circumstance 5 conclusion paper conducted experiment discovering possibility autoencoderbased feature extraction joint optimization method automated detection atypicality voice child asd early developmental stage condition insu cient dispersed data set classiﬁcation result relatively poor comparison general classiﬁcation task based deep learning although investigation used limited number subject unbalanced data set suggested autoencoderbased feature extraction joint optimization method revealed possibility feature dimension slight improvement modelbased diagnosis uncertain circumstance future work focus increasing reliability proposed method addition number infant speech data reﬁnement acoustic feature autoencoder feature extraction better deeper uptodate model structure research also extended child age 3 4 speak several sentence case investigate linguistic feature well acoustic feature done paper addition asd detection research applied detection infant development delay author contribution author discussed content manuscript hkk contributed research idea framework study gb hjy provided database helped discussion jhl performed experiment gwl contributed data collection preprocessing author read agreed published version manuscript funding work supported institute information communication technology planning evaluation grant funded korea government conﬂicts interest author declare conﬂict interestsensors 2020 20 6762 10 11 reference 1 national institute mental health autism spectrum disorder available online http wwwnimhnih govhealth topic autismspectrumdisordersasd indexshtml 2 american psychiatric association diagnostic statistical manual mental disorder dsm5 american psychiatric publishing washington dc usa 2013 3 center disease control prevention data statistic autism spectrum disorder available online http wwwcdcgov ncbddd autism datahtml 4 fenske ec zalenski krantz p j mcclannahan le age intervention treatment outcome autistic child comprehensive intervention program anal interv devel disabil 1985 5 4958 crossref 5 falkmer anderson k falkmer horlin c diagnostic procedure autism spectrum disorder systematic literature review eur child adolesc psychiatry 2013 22 329340 crossref pubmed 6 bailey le couteur gottesman bolton p simono e yuzda e rutter autism strongly genetic disorder evidence british twin study physiol med 1995 25 6377 crossref pubmed 7 du fh al h stable pattern eeg spectral coherence distinguishes child autism neurotypical controlsa large case control study bmc med 2012 10 64 crossref pubmed 8 chaspari lee cc narayanan s interplay verbal response latency physiology child autism eca interaction proceeding annual conference international speech communication association portland usa 913 september 2012 pp 13191322 9 baroncohen social pragmatic deﬁcits autism cognitive ective j autism dev disord 1988 18 379402 crossref pubmed 10 bonneh y levanon deanpardo lossos l adini abnormal speech spectrum increased pitch variability young autistic child front hum neurosci 2011 4 237 crossref pubmed 11 chericoni n de brito wanderley costanzo v dinizgonçalves gille ml parlato e cohen apicella f calderoni muratori f prelinguistic vocal trajectory 618 month age early marker autism front psychol 2016 7 1595 crossref pubmed 12 alom mz taha tm yakopcic c westberg sidike p nasrin m hasan van essen bc awwal aa asari v k stateoftheart survey deep learning theory architecture electronics 2019 8 292 crossref 13 song dy kim sy bong g kim jm yoo hj use artiﬁcial intelligence screening diagnosis autism spectrum disorder literature review j korean acad child adolesc psychiatry 2019 30 145152 crossref pubmed 14 santos jf brosh n falk th zwaigenbaum l bryson se robert w smith im szatmari p brian ja early detection autism spectrum disorder based acoustic analysis preverbal vocalization 18month old toddler proceeding ieee international conference acoustic speech signal processing vancouver bc canada 2631 may 2013 pp 75677571 15 li tang zeng j zhou zhu h chen b zou x automated assessment framework atypical prosody stereotyped idiosyncratic phrase related autism spectrum disorder comput speech lang 2019 56 8094 crossref 16 eyben f scherer kr schuller bw sundberg j andr é e busso c devillers ly epps j laukka p narayanan s et al geneva minimalistic acoustic parameter set voice research ective computing ieee trans ect comput 2016 7 190202 crossref 17 pokorny fb schuller bw marschik p b brueckner r nyström p cummins n bölte einspieler c falckytter earlier identiﬁcation child autism spectrum disorder automatic vocalisationbased approach proceeding annual conference international speech communication association stockholm sweden 2024 august 2017 pp 309313 18 xing c l yang x stacked denoise autoencoder based feature extraction classiﬁcation hyperspectral image j sen 2016 2016 3632943 crossref 19 bong g kim j hong yoon n sunwoo h jang j oh lee k jung yoo h feasibility validity autism spectrum disorder screening instrument behavior development screening toddler pilot study autism re 2019 12 11121128 crossref pubmedsensors 2020 20 6762 11 11 20 center autism research social communication questionnaire available online http www carautismroadmaporg socialcommunicationquestionnairescq print pdf 21 center autism research childhood autism rating scale 2nd edition available online http wwwcarautismroadmaporg childhoodautismratingscale print pdf 22 center autism research social responsiveness scale 2nd edition available online http wwwcarautismroadmaporg socialresponsivenessscale print pdf 23 eyben f wöllmer schuller b opensmilethe munich versatile fast opensource audio feature extractor proceeding 18th acm international conference multimedia firenze italy 2529 october 2010 pp 14591462 24 masci j meier u cire san schmidhuber j stacked convolutional autoencoders hierarchical feature extraction artiﬁcial neural network machineicann 2011 honkela duch w girolami kaski ed springer berlin heidelberg germany 2011 pp 5259 25 sainath kingsbury b ramabhadran b autoencoder bottleneck feature using deep belief network proceeding 2012 ieee international conference acoustic speech signal processing kyoto japan 2530 march 2012 26 nachar n mannwhitney u test assessing whether two independent sample come distribution tutor quant method psychol 2008 4 1320 crossref 27 le l patterson white supervised autoencoders improving generalization performance unsupervised regularizers advance neural information processing system bengio wallach h larochelle h grauman k cesabianchi n garnett r ed curran associate inc new york ny usa 2018 pp 107117 28 van laarhoven l2 regularization versus batch weight normalization arxiv 2017 arxiv170605350 29 io e szegedy c batch normalization accelerating deep network training reducing internal covariate shift proceeding international conference machine learning lille france 611 july 2015 pp 448456 30 nair v hinton ge rectiﬁed linear unit improve restricted boltzmann machine proceeding 27th international conference machine learning haifa israel 2124 june 2010 pp 807814 31 srivastava n hinton g krizhevsky sutskever salakhutdinov r dropout simple way prevent neural network overﬁtting j mach learn re 2014 15 9291958 32 kingma dp ba jl adam method stochastic optimization proceeding 3rd international conference learning representation san diego ca usa 79 may 2015 pp 115 33 abadi barham p chen j chen z davis dean j devin ghemawat irving g isard et al tensorflow system largescale machine learning proceeding 12th usenix symposium operating system design implementation savannah ga usa 24 november 2016 pp 265283 34 schuller b steidl batliner interspeech 2009 emotion challenge proceeding annual conference international speech communication association brighton uk 610 september 2009 pp 312315 35 van der maaten l hinton g visualizing data using tsne j mach learn re 2008 9 25792605 publisher note mdpi stay neutral regard jurisdictional claim published map institutional aliations 2020 author licensee mdpi basel switzerland article open access article distributed term condition creative common attribution license